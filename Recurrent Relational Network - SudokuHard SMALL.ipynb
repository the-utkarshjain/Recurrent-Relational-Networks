{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJFd7JS7zEvw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/Shareddrives/')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUSjYtr-z09T",
        "outputId": "88021b6c-7ad4-44cf-ea40-18709284c8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.dataframe = pd.read_csv(filepath, header = None)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataframe.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        unsolved_sudoku = self.dataframe.iloc[idx,0]\n",
        "        unsolved_sudoku = [int(cell) for cell in unsolved_sudoku]\n",
        "\n",
        "        target = self.dataframe.iloc[idx, 1]\n",
        "        target = [int(cell) for cell in target]\n",
        "        \n",
        "        return torch.tensor(unsolved_sudoku, dtype = torch.long), torch.tensor(target, dtype = torch.long)\n",
        "\n",
        "train_dataset = CustomDataset('./sudoku-hard/train.csv')\n",
        "test_dataset = CustomDataset('./sudoku-hard/test.csv')"
      ],
      "metadata": {
        "id": "NP_BzmiVz5xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_row(row):\n",
        "  return [9*row + i for i in range(9)]\n",
        "\n",
        "def calc_col(col):\n",
        "  return [col + 9*i for i in range(9)]\n",
        "\n",
        "def calc_grid(gridx, gridy):\n",
        "  lis = np.array([[0,1,2], [9,10,11], [18,19,20]])\n",
        "  lis = np.array([27*gridx + x for x in lis])\n",
        "  lis = np.array([3*gridy + x for x in lis])\n",
        "  return list(lis.reshape(-1))\n",
        "\n",
        "def sudoku_edges():\n",
        "  src_ids = []\n",
        "  dest_ids = []\n",
        "\n",
        "  for i in range(81):\n",
        "    src_id = [i]*20\n",
        "    row, col = int(np.floor(i/9)), int(np.floor((i%9)))\n",
        "    gridx, gridy = int(np.floor(row/3)), int(np.floor(col/3))\n",
        "\n",
        "    rows = calc_row(row)\n",
        "    cols = calc_col(col)\n",
        "    grids = calc_grid(gridx, gridy)\n",
        "\n",
        "    dest_id = list(set(rows + cols + grids).difference(set([i])))\n",
        "    dest_id.sort()\n",
        "    src_ids += src_id\n",
        "    dest_ids += dest_id\n",
        "\n",
        "  return torch.tensor(src_ids, dtype = torch.long), torch.tensor(dest_ids, dtype = torch.long)"
      ],
      "metadata": {
        "id": "8OOp2n000KpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  digits = []\n",
        "  rows = []\n",
        "  cols = [] \n",
        "  src_edges = []\n",
        "  dest_edges = []\n",
        "  labels = []\n",
        "\n",
        "  row = [0]*9 + [1]*9 + [2]*9 + [3]*9 + [4]*9 + [5]*9 + [6]*9 + [7]*9 + [8]*9\n",
        "  col = [0,1,2,3,4,5,6,7,8]*9\n",
        "  src_ids, dest_ids = sudoku_edges()\n",
        "\n",
        "  for i, (x, y) in enumerate(batch):\n",
        "    digits.append(x)\n",
        "\n",
        "    rows.append(torch.tensor(row, dtype = torch.long))\n",
        "    cols.append(torch.tensor(col, dtype = torch.long))\n",
        "    \n",
        "    src_edges.append(src_ids + 81*i)\n",
        "    dest_edges.append(dest_ids + 81*i)\n",
        "\n",
        "    labels.append(y)\n",
        "\n",
        "  return torch.cat(digits).to(device), torch.cat(rows).to(device), torch.cat(cols).to(device), torch.cat(labels).to(device), torch.cat(src_edges).to(device), torch.cat(dest_edges).to(device)\n",
        "\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, collate_fn = collate_fn, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, collate_fn = collate_fn, shuffle = True)"
      ],
      "metadata": {
        "id": "LYmb6dl90MwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RRN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding_dim = 16\n",
        "    self.message_size = 96\n",
        "    self.node_hidden_state_size = 96\n",
        "    self.n_iters = 32\n",
        "\n",
        "    self.digit_embedding = nn.Embedding(10, self.embedding_dim)\n",
        "    self.row_embedding = nn.Embedding(9, self.embedding_dim)\n",
        "    self.col_embedding = nn.Embedding(9, self.embedding_dim)\n",
        "\n",
        "    self.mlp1 = nn.Sequential(\n",
        "        nn.Linear(self.embedding_dim, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, self.node_hidden_state_size)\n",
        "    )\n",
        "\n",
        "    self.message_network = nn.Sequential(\n",
        "        nn.Linear(2*self.node_hidden_state_size, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, self.message_size)\n",
        "    )\n",
        "\n",
        "    self.gru = nn.GRU(2*self.message_size, self.node_hidden_state_size)\n",
        "\n",
        "    self.linear = nn.Linear(self.node_hidden_state_size, 10)\n",
        "\n",
        "  def forward(self, digits, rows, cols, src_edges, dest_edges):\n",
        "    output_from_each_iter = []\n",
        "\n",
        "    embedded_digits = self.digit_embedding(digits)\n",
        "    x = self.mlp1(embedded_digits)\n",
        "    initial_hidden_states = x.unsqueeze(0)\n",
        "\n",
        "    for i in range(self.n_iters):\n",
        "      src_encodings = torch.index_select(initial_hidden_states[0], dim = 0, index = src_edges)\n",
        "      dest_encodings = torch.index_select(initial_hidden_states[0], dim = 0, index = dest_edges)\n",
        "      \n",
        "      input_to_message_network = torch.cat([src_encodings, dest_encodings], dim = -1)\n",
        "      output_from_message_network = self.message_network(input_to_message_network)\n",
        "      aggregated_messages = torch.zeros(x.shape[0], self.message_size).to(device)\n",
        "      aggregated_messages.index_add_(0, dest_edges, output_from_message_network)\n",
        "\n",
        "      input_to_gru = torch.cat((x, aggregated_messages), dim = -1).unsqueeze(0)\n",
        "      output_from_gru, initial_hidden_states = self.gru(input_to_gru, initial_hidden_states)\n",
        "\n",
        "      output_from_linear = self.linear(output_from_gru.squeeze(0))\n",
        "      \n",
        "      output_from_each_iter.append(output_from_linear)\n",
        "    \n",
        "    return output_from_each_iter"
      ],
      "metadata": {
        "id": "Axiw5T6G0O1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_v2(model):\n",
        "  total_solved = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  solved_givens = torch.zeros(18, device = device)\n",
        "  correct_givens = torch.zeros(18, device = device)\n",
        "\n",
        "  for (digits, rows, cols, target, src_edges, dest_edges) in test_dataloader:\n",
        "    batch_size = digits.shape[0] // 81\n",
        "\n",
        "    reshaped_digits = digits.reshape(-1, 81)\n",
        "    is_not_zeros = (reshaped_digits != 0).sum(dim = -1)\n",
        "\n",
        "    output_from_each_iter = model(digits, rows, cols, src_edges, dest_edges)\n",
        "    output_from_last_iter = output_from_each_iter[-1]\n",
        "    predictions = output_from_last_iter.argmax(dim = -1)\n",
        "\n",
        "    predictions = predictions.view(batch_size, -1)\n",
        "    target = target.view(batch_size, -1)\n",
        "\n",
        "    is_correct = (predictions == target).all(dim = -1)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      solved_givens[is_not_zeros[i] - 17] += 1\n",
        "      if(is_correct[i] == True):\n",
        "        correct_givens[is_not_zeros[i] - 17] += 1\n",
        "\n",
        "    total_solved += batch_size\n",
        "    total_correct += is_correct.sum().item()\n",
        "  \n",
        "  return total_correct*100 / total_solved, solved_givens, correct_givens\n",
        "\n",
        "def train_v2(model, criterion, optimizer, epochs = 35, resuming = -1, print_every = len(train_dataloader) // 10):\n",
        "  for epoch in range(resuming+1, epochs):\n",
        "    loss_per_epoch = 0\n",
        "    loss_per_print_every = 0\n",
        "    count = 0\n",
        "    for itr, (digits, rows, cols, target, src_edges, dest_edges) in enumerate(train_dataloader):\n",
        "      output_from_each_iter = model(digits, rows, cols, src_edges, dest_edges)\n",
        "      \n",
        "      loss = 0\n",
        "      for output_on_each_iter in output_from_each_iter:\n",
        "        loss += criterion(output_on_each_iter, target)\n",
        "      \n",
        "      loss = loss/model.n_iters\n",
        "      loss_per_epoch += loss\n",
        "      loss_per_print_every += loss\n",
        "      count += 1\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (itr+1)%print_every == 0:\n",
        "        print(f\"Epoch: {epoch} \\t itr: {itr}/{len(train_dataloader)} \\t loss: {loss_per_print_every / count}\")\n",
        "        loss_per_print_every = 0\n",
        "        count = 0\n",
        "    \n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'epoch': epoch\n",
        "            }, './smaller-model/small' + str(epoch) + '.pth')\n",
        "    \n",
        "    print()\n",
        "    print(f\"Epoch: {epoch} \\t loss: {loss_per_epoch / len(train_dataloader)}\")\n",
        "    model.eval()\n",
        "    acc, solved_givens, correct_givens = evaluate_v2(model)\n",
        "    print(\"Testing Summary\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"Correct Givens: \", correct_givens)\n",
        "    print(\"Solved Givens: \", solved_givens)\n",
        "    model.train()\n",
        "    print()"
      ],
      "metadata": {
        "id": "2vjLj58O0R9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rrn = RRN2().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params = rrn.parameters(), lr = 2e-4, weight_decay = 1e-4)\n",
        "\n",
        "checkpoint = torch.load('./smaller-model/small11.pth')\n",
        "rrn.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "m3oQhikYvb6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_v2(rrn, criterion, optimizer, resuming = epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Rke_srxG8-",
        "outputId": "4ae5e7b6-68a6-4d3c-fa87-b0c6d5a52cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 \t itr: 1124/11250 \t loss: 0.21675893664360046\n",
            "Epoch: 12 \t itr: 2249/11250 \t loss: 0.23241297900676727\n",
            "Epoch: 12 \t itr: 3374/11250 \t loss: 0.20284612476825714\n",
            "Epoch: 12 \t itr: 4499/11250 \t loss: 0.21185921132564545\n",
            "Epoch: 12 \t itr: 5624/11250 \t loss: 0.21363408863544464\n",
            "Epoch: 12 \t itr: 6749/11250 \t loss: 0.20907045900821686\n",
            "Epoch: 12 \t itr: 7874/11250 \t loss: 0.20879840850830078\n",
            "Epoch: 12 \t itr: 8999/11250 \t loss: 0.20390784740447998\n",
            "Epoch: 12 \t itr: 10124/11250 \t loss: 0.19893738627433777\n",
            "Epoch: 12 \t itr: 11249/11250 \t loss: 0.19959820806980133\n",
            "\n",
            "Epoch: 12 \t loss: 0.2097821831703186\n",
            "Testing Summary\n",
            "Accuracy: 91.97777777777777\n",
            "Correct Givens:  tensor([ 573.,  677.,  778.,  850.,  882.,  933.,  949.,  980.,  974.,  987.,\n",
            "         992.,  991.,  995.,  997.,  999.,  999., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "Solved Givens:  tensor([1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
            "        1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "\n",
            "Epoch: 13 \t itr: 1124/11250 \t loss: 0.2055812031030655\n",
            "Epoch: 13 \t itr: 2249/11250 \t loss: 0.20721589028835297\n",
            "Epoch: 13 \t itr: 3374/11250 \t loss: 0.20844551920890808\n",
            "Epoch: 13 \t itr: 4499/11250 \t loss: 0.2042020559310913\n",
            "Epoch: 13 \t itr: 5624/11250 \t loss: 0.20048393309116364\n",
            "Epoch: 13 \t itr: 6749/11250 \t loss: 0.19619685411453247\n",
            "Epoch: 13 \t itr: 7874/11250 \t loss: 0.19582203030586243\n",
            "Epoch: 13 \t itr: 8999/11250 \t loss: 0.1966688185930252\n",
            "Epoch: 13 \t itr: 10124/11250 \t loss: 0.20131424069404602\n",
            "Epoch: 13 \t itr: 11249/11250 \t loss: 0.18714416027069092\n",
            "\n",
            "Epoch: 13 \t loss: 0.2003074437379837\n",
            "Testing Summary\n",
            "Accuracy: 91.21666666666667\n",
            "Correct Givens:  tensor([ 566.,  679.,  745.,  826.,  857.,  914.,  944.,  963.,  973.,  980.,\n",
            "         990.,  994.,  992.,  997.,  999., 1000., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "Solved Givens:  tensor([1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
            "        1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "\n",
            "Epoch: 14 \t itr: 1124/11250 \t loss: 0.20022982358932495\n",
            "Epoch: 14 \t itr: 2249/11250 \t loss: 0.19364483654499054\n",
            "Epoch: 14 \t itr: 3374/11250 \t loss: 0.1893867403268814\n",
            "Epoch: 14 \t itr: 4499/11250 \t loss: 0.19388647377490997\n",
            "Epoch: 14 \t itr: 5624/11250 \t loss: 0.19939720630645752\n",
            "Epoch: 14 \t itr: 6749/11250 \t loss: 0.19913943111896515\n",
            "Epoch: 14 \t itr: 7874/11250 \t loss: 0.1955559402704239\n",
            "Epoch: 14 \t itr: 8999/11250 \t loss: 0.19256077706813812\n",
            "Epoch: 14 \t itr: 10124/11250 \t loss: 0.19514724612236023\n",
            "Epoch: 14 \t itr: 11249/11250 \t loss: 0.19838890433311462\n",
            "\n",
            "Epoch: 14 \t loss: 0.19573402404785156\n",
            "Testing Summary\n",
            "Accuracy: 91.41666666666667\n",
            "Correct Givens:  tensor([ 532.,  663.,  745.,  827.,  872.,  932.,  957.,  976.,  977.,  987.,\n",
            "         996.,  993.,  998., 1000., 1000., 1000., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "Solved Givens:  tensor([1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
            "        1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
            "       device='cuda:0')\n",
            "\n",
            "Epoch: 15 \t itr: 1124/11250 \t loss: 0.187009796500206\n",
            "Epoch: 15 \t itr: 2249/11250 \t loss: 0.18912340700626373\n",
            "Epoch: 15 \t itr: 3374/11250 \t loss: 0.19696593284606934\n",
            "Epoch: 15 \t itr: 4499/11250 \t loss: 0.19015206396579742\n",
            "Epoch: 15 \t itr: 5624/11250 \t loss: 0.1912907510995865\n"
          ]
        }
      ]
    }
  ]
}
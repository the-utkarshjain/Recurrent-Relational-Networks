{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qifx33is96WP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "2BGCl7D5-K-l",
        "outputId": "32eb4470-04d2-4834-b539-0ef1e16160be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.load('./sudoku/features.pt')\n",
        "Y = torch.load('./sudoku/labels.pt')"
      ],
      "metadata": {
        "id": "xTjUjV0m-ve8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_test(X, Y):\n",
        "  X = torch.flatten(X, start_dim = -3, end_dim = -2)\n",
        "  Y = torch.argmax(Y, dim = -1).flatten(start_dim = -2)\n",
        "\n",
        "  X_train = X[:9000]\n",
        "  Y_train = Y[:9000]\n",
        "\n",
        "  X_test = X[9000:]\n",
        "  Y_test = Y[9000:]\n",
        "\n",
        "  training_list = [(X_train[i],Y_train[i]) for i in range(X_train.shape[0])]\n",
        "  testing_list = [(X_test[i],Y_test[i]) for i in range(X_test.shape[0])]\n",
        "\n",
        "  return training_list, testing_list\n",
        "\n",
        "training_set, testing_set = generate_train_test(X, Y)"
      ],
      "metadata": {
        "id": "kD3lVJk2_Qfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_row(row):\n",
        "  return [9*row + i for i in range(9)]\n",
        "\n",
        "def calc_col(col):\n",
        "  return [col + 9*i for i in range(9)]\n",
        "\n",
        "def calc_grid(gridx, gridy):\n",
        "  lis = np.array([[0,1,2], [9,10,11], [18,19,20]])\n",
        "  lis = np.array([27*gridx + x for x in lis])\n",
        "  lis = np.array([3*gridy + x for x in lis])\n",
        "  return list(lis.reshape(-1))\n",
        "\n",
        "def sudoku_edges():\n",
        "  src_ids = []\n",
        "  dest_ids = []\n",
        "\n",
        "  for i in range(81):\n",
        "    src_id = [i]*20\n",
        "    row, col = int(np.floor(i/9)), int(np.floor((i%9)))\n",
        "    gridx, gridy = int(np.floor(row/3)), int(np.floor(col/3))\n",
        "\n",
        "    rows = calc_row(row)\n",
        "    cols = calc_col(col)\n",
        "    grids = calc_grid(gridx, gridy)\n",
        "\n",
        "    dest_id = list(set(rows + cols + grids).difference(set([i])))\n",
        "    dest_id.sort()\n",
        "    src_ids += src_id\n",
        "    dest_ids += dest_id\n",
        "\n",
        "  return torch.tensor(src_ids, dtype = torch.long), torch.tensor(dest_ids, dtype = torch.long)"
      ],
      "metadata": {
        "id": "_rA-yOqzEvUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  features = []\n",
        "  labels = []\n",
        "  src_edges = []\n",
        "  dest_edges = []\n",
        "\n",
        "  src_ids, dest_ids = sudoku_edges()\n",
        "\n",
        "  for i, (x, y) in enumerate(batch):\n",
        "    features.append(x)\n",
        "    labels.append(y)\n",
        "    src_edges.append(src_ids + 81*i)\n",
        "    dest_edges.append(dest_ids + 81*i)\n",
        "  \n",
        "  return torch.cat(features, dim = 0).to(device), torch.cat(labels).to(device), torch.cat(src_edges).to(device), torch.cat(dest_edges).to(device)\n",
        "\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(training_set, batch_size = batch_size, collate_fn = collate_fn)\n",
        "test_dataloader = DataLoader(testing_set, batch_size = batch_size, collate_fn = collate_fn)"
      ],
      "metadata": {
        "id": "AKMUQTOUFYta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RRN(nn.Module):\n",
        "  def __init__(self, node_hidden_state_size, message_size, n_iters):\n",
        "    super(RRN, self).__init__()\n",
        "    self.node_hidden_state_size = node_hidden_state_size\n",
        "    self.message_size = message_size\n",
        "    self.n_iters = n_iters\n",
        "\n",
        "    self.message_network = nn.Sequential(\n",
        "        nn.Linear(2*self.node_hidden_state_size, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, 96),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(96, self.message_size)\n",
        "    )\n",
        "\n",
        "    self.gru = nn.GRU(9+self.message_size, self.node_hidden_state_size)\n",
        "\n",
        "    self.linear = nn.Linear(self.node_hidden_state_size, 9)\n",
        "\n",
        "  def forward(self, features, src_edges, dest_edges):\n",
        "    output_from_each_iter = []\n",
        "    initial_hidden_states = torch.zeros(1, features.shape[0], self.node_hidden_state_size).to(device)\n",
        "\n",
        "    for i in range(self.n_iters):\n",
        "      src_encodings = torch.index_select(initial_hidden_states[0], dim = 0, index = src_edges)\n",
        "      dest_encodings = torch.index_select(initial_hidden_states[0], dim = 0, index = dest_edges)\n",
        "      \n",
        "      input_to_message_network = torch.cat([src_encodings, dest_encodings], dim = -1)\n",
        "      output_from_message_network = self.message_network(input_to_message_network)\n",
        "      aggregated_messages = torch.zeros(features.shape[0], self.message_size).to(device)\n",
        "      aggregated_messages.index_add_(0, dest_edges, output_from_message_network)\n",
        "\n",
        "      input_to_gru = torch.cat((features, aggregated_messages), dim = -1).unsqueeze(0)\n",
        "      output_from_gru, initial_hidden_states = self.gru(input_to_gru, initial_hidden_states)\n",
        "\n",
        "      output_from_linear = self.linear(output_from_gru.squeeze(0))\n",
        "      \n",
        "      output_from_each_iter.append(output_from_linear)\n",
        "    \n",
        "    return output_from_each_iter"
      ],
      "metadata": {
        "id": "CJlvic87phkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "  total_solved = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  for (features, target, src_edges, dest_edges) in test_dataloader:\n",
        "    batch_size = features.shape[0] // 81\n",
        "    output_from_each_iter = model(features, src_edges, dest_edges)\n",
        "    output_from_last_iter = output_from_each_iter[-1]\n",
        "    predictions = output_from_last_iter.argmax(dim = -1)\n",
        "\n",
        "    predictions = predictions.view(batch_size, -1)\n",
        "    target = target.view(batch_size, -1)\n",
        "\n",
        "    is_correct = (predictions == target).all(dim = -1)\n",
        "    total_solved += batch_size\n",
        "    total_correct += is_correct.sum().item()\n",
        "  \n",
        "  return total_correct / total_solved\n",
        "\n",
        "def train(model, epochs, print_every):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(params = model.parameters())\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss_per_epoch = 0\n",
        "    loss_per_print_every = 0\n",
        "    count = 0\n",
        "    for itr, (features, target, src_edges, dest_edges) in enumerate(train_dataloader):\n",
        "      output_from_each_iter = model(features, src_edges, dest_edges)\n",
        "      \n",
        "      loss = 0\n",
        "      for output_on_each_iter in output_from_each_iter:\n",
        "        loss += criterion(output_on_each_iter, target)\n",
        "      \n",
        "      loss = loss/model.n_iters\n",
        "      loss_per_epoch += loss\n",
        "      loss_per_print_every += loss\n",
        "      count += 1\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (itr+1)%print_every == 0:\n",
        "        print(f\"Epoch: {epoch} \\t itr: {itr}/{len(train_dataloader)} \\t loss: {loss_per_print_every / count}\")\n",
        "        loss_per_print_every = 0\n",
        "        count = 0\n",
        "    \n",
        "    print()\n",
        "    print(f\"Epoch: {epoch} \\t loss: {loss_per_epoch / len(train_dataloader)}\")\n",
        "    model.eval()\n",
        "    print(\"Test set: \", evaluate(model))\n",
        "    model.train()\n",
        "    print()\n",
        "\n",
        "rrn = RRN(10, 11, 7).to(device)\n",
        "train(rrn, 30, len(train_dataloader) // 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiqcfd39qBKh",
        "outputId": "3df0aa0f-6dd5-488b-81e0-d3b2930e326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \t itr: 55/563 \t loss: 2.02996826171875\n",
            "Epoch: 0 \t itr: 111/563 \t loss: 1.6108664274215698\n",
            "Epoch: 0 \t itr: 167/563 \t loss: 1.4488059282302856\n",
            "Epoch: 0 \t itr: 223/563 \t loss: 1.3424004316329956\n",
            "Epoch: 0 \t itr: 279/563 \t loss: 1.2526931762695312\n",
            "Epoch: 0 \t itr: 335/563 \t loss: 1.1896731853485107\n",
            "Epoch: 0 \t itr: 391/563 \t loss: 1.1018798351287842\n",
            "Epoch: 0 \t itr: 447/563 \t loss: 0.9866963028907776\n",
            "Epoch: 0 \t itr: 503/563 \t loss: 0.8844743371009827\n",
            "Epoch: 0 \t itr: 559/563 \t loss: 0.8334901928901672\n",
            "\n",
            "Epoch: 0 \t loss: 1.2654423713684082\n",
            "Test set:  0.0\n",
            "\n",
            "Epoch: 1 \t itr: 55/563 \t loss: 0.7123574614524841\n",
            "Epoch: 1 \t itr: 111/563 \t loss: 0.6369412541389465\n",
            "Epoch: 1 \t itr: 167/563 \t loss: 0.590373694896698\n",
            "Epoch: 1 \t itr: 223/563 \t loss: 0.551932692527771\n",
            "Epoch: 1 \t itr: 279/563 \t loss: 0.5230867266654968\n",
            "Epoch: 1 \t itr: 335/563 \t loss: 0.48592665791511536\n",
            "Epoch: 1 \t itr: 391/563 \t loss: 0.4646262228488922\n",
            "Epoch: 1 \t itr: 447/563 \t loss: 0.4578646123409271\n",
            "Epoch: 1 \t itr: 503/563 \t loss: 0.4324181079864502\n",
            "Epoch: 1 \t itr: 559/563 \t loss: 0.4193422198295593\n",
            "\n",
            "Epoch: 1 \t loss: 0.526901364326477\n",
            "Test set:  0.586\n",
            "\n",
            "Epoch: 2 \t itr: 55/563 \t loss: 0.4054926335811615\n",
            "Epoch: 2 \t itr: 111/563 \t loss: 0.3823228180408478\n",
            "Epoch: 2 \t itr: 167/563 \t loss: 0.36868196725845337\n",
            "Epoch: 2 \t itr: 223/563 \t loss: 0.3575306236743927\n",
            "Epoch: 2 \t itr: 279/563 \t loss: 0.3505106270313263\n",
            "Epoch: 2 \t itr: 335/563 \t loss: 0.33852463960647583\n",
            "Epoch: 2 \t itr: 391/563 \t loss: 0.3315677046775818\n",
            "Epoch: 2 \t itr: 447/563 \t loss: 0.329429566860199\n",
            "Epoch: 2 \t itr: 503/563 \t loss: 0.3268100917339325\n",
            "Epoch: 2 \t itr: 559/563 \t loss: 0.31862807273864746\n",
            "\n",
            "Epoch: 2 \t loss: 0.3507615029811859\n",
            "Test set:  0.878\n",
            "\n",
            "Epoch: 3 \t itr: 55/563 \t loss: 0.3196784555912018\n",
            "Epoch: 3 \t itr: 111/563 \t loss: 0.3139270544052124\n",
            "Epoch: 3 \t itr: 167/563 \t loss: 0.30817216634750366\n",
            "Epoch: 3 \t itr: 223/563 \t loss: 0.3082815706729889\n",
            "Epoch: 3 \t itr: 279/563 \t loss: 0.311058908700943\n",
            "Epoch: 3 \t itr: 335/563 \t loss: 0.30103427171707153\n",
            "Epoch: 3 \t itr: 391/563 \t loss: 0.30011221766471863\n",
            "Epoch: 3 \t itr: 447/563 \t loss: 0.300166517496109\n",
            "Epoch: 3 \t itr: 503/563 \t loss: 0.300565630197525\n",
            "Epoch: 3 \t itr: 559/563 \t loss: 0.294826477766037\n",
            "\n",
            "Epoch: 3 \t loss: 0.30571019649505615\n",
            "Test set:  0.912\n",
            "\n",
            "Epoch: 4 \t itr: 55/563 \t loss: 0.2978045642375946\n",
            "Epoch: 4 \t itr: 111/563 \t loss: 0.29408639669418335\n",
            "Epoch: 4 \t itr: 167/563 \t loss: 0.2904784381389618\n",
            "Epoch: 4 \t itr: 223/563 \t loss: 0.29082003235816956\n",
            "Epoch: 4 \t itr: 279/563 \t loss: 0.2931952476501465\n",
            "Epoch: 4 \t itr: 335/563 \t loss: 0.2874053418636322\n",
            "Epoch: 4 \t itr: 391/563 \t loss: 0.28609204292297363\n",
            "Epoch: 4 \t itr: 447/563 \t loss: 0.2861579656600952\n",
            "Epoch: 4 \t itr: 503/563 \t loss: 0.2867564260959625\n",
            "Epoch: 4 \t itr: 559/563 \t loss: 0.283166766166687\n",
            "\n",
            "Epoch: 4 \t loss: 0.28953826427459717\n",
            "Test set:  0.935\n",
            "\n",
            "Epoch: 5 \t itr: 55/563 \t loss: 0.2862624526023865\n",
            "Epoch: 5 \t itr: 111/563 \t loss: 0.2826380729675293\n",
            "Epoch: 5 \t itr: 167/563 \t loss: 0.280255526304245\n",
            "Epoch: 5 \t itr: 223/563 \t loss: 0.28102296590805054\n",
            "Epoch: 5 \t itr: 279/563 \t loss: 0.28454872965812683\n",
            "Epoch: 5 \t itr: 335/563 \t loss: 0.2791832685470581\n",
            "Epoch: 5 \t itr: 391/563 \t loss: 0.27899953722953796\n",
            "Epoch: 5 \t itr: 447/563 \t loss: 0.2783737778663635\n",
            "Epoch: 5 \t itr: 503/563 \t loss: 0.2790919542312622\n",
            "Epoch: 5 \t itr: 559/563 \t loss: 0.2763449549674988\n",
            "\n",
            "Epoch: 5 \t loss: 0.2806108891963959\n",
            "Test set:  0.955\n",
            "\n",
            "Epoch: 6 \t itr: 55/563 \t loss: 0.278205007314682\n",
            "Epoch: 6 \t itr: 111/563 \t loss: 0.2755514681339264\n",
            "Epoch: 6 \t itr: 167/563 \t loss: 0.274642676115036\n",
            "Epoch: 6 \t itr: 223/563 \t loss: 0.2745945453643799\n",
            "Epoch: 6 \t itr: 279/563 \t loss: 0.27733877301216125\n",
            "Epoch: 6 \t itr: 335/563 \t loss: 0.2735273838043213\n",
            "Epoch: 6 \t itr: 391/563 \t loss: 0.2732224464416504\n",
            "Epoch: 6 \t itr: 447/563 \t loss: 0.2729467749595642\n",
            "Epoch: 6 \t itr: 503/563 \t loss: 0.27299556136131287\n",
            "Epoch: 6 \t itr: 559/563 \t loss: 0.27199918031692505\n",
            "\n",
            "Epoch: 6 \t loss: 0.27445125579833984\n",
            "Test set:  0.964\n",
            "\n",
            "Epoch: 7 \t itr: 55/563 \t loss: 0.27305659651756287\n",
            "Epoch: 7 \t itr: 111/563 \t loss: 0.2704983353614807\n",
            "Epoch: 7 \t itr: 167/563 \t loss: 0.26980477571487427\n",
            "Epoch: 7 \t itr: 223/563 \t loss: 0.2710312306880951\n",
            "Epoch: 7 \t itr: 279/563 \t loss: 0.2739596664905548\n",
            "Epoch: 7 \t itr: 335/563 \t loss: 0.269094854593277\n",
            "Epoch: 7 \t itr: 391/563 \t loss: 0.2697981297969818\n",
            "Epoch: 7 \t itr: 447/563 \t loss: 0.2686549127101898\n",
            "Epoch: 7 \t itr: 503/563 \t loss: 0.2684839367866516\n",
            "Epoch: 7 \t itr: 559/563 \t loss: 0.26832056045532227\n",
            "\n",
            "Epoch: 7 \t loss: 0.2702172100543976\n",
            "Test set:  0.97\n",
            "\n",
            "Epoch: 8 \t itr: 55/563 \t loss: 0.2692098021507263\n",
            "Epoch: 8 \t itr: 111/563 \t loss: 0.2666175067424774\n",
            "Epoch: 8 \t itr: 167/563 \t loss: 0.2663542330265045\n",
            "Epoch: 8 \t itr: 223/563 \t loss: 0.2668687105178833\n",
            "Epoch: 8 \t itr: 279/563 \t loss: 0.26921436190605164\n",
            "Epoch: 8 \t itr: 335/563 \t loss: 0.26539039611816406\n",
            "Epoch: 8 \t itr: 391/563 \t loss: 0.2656852602958679\n",
            "Epoch: 8 \t itr: 447/563 \t loss: 0.26527589559555054\n",
            "Epoch: 8 \t itr: 503/563 \t loss: 0.26521676778793335\n",
            "Epoch: 8 \t itr: 559/563 \t loss: 0.26461413502693176\n",
            "\n",
            "Epoch: 8 \t loss: 0.2664051055908203\n",
            "Test set:  0.969\n",
            "\n",
            "Epoch: 9 \t itr: 55/563 \t loss: 0.26654407382011414\n",
            "Epoch: 9 \t itr: 111/563 \t loss: 0.2640824317932129\n",
            "Epoch: 9 \t itr: 167/563 \t loss: 0.2636389136314392\n",
            "Epoch: 9 \t itr: 223/563 \t loss: 0.2634553909301758\n",
            "Epoch: 9 \t itr: 279/563 \t loss: 0.26521167159080505\n",
            "Epoch: 9 \t itr: 335/563 \t loss: 0.26191163063049316\n",
            "Epoch: 9 \t itr: 391/563 \t loss: 0.26245683431625366\n",
            "Epoch: 9 \t itr: 447/563 \t loss: 0.2626025378704071\n",
            "Epoch: 9 \t itr: 503/563 \t loss: 0.26337847113609314\n",
            "Epoch: 9 \t itr: 559/563 \t loss: 0.26203230023384094\n",
            "\n",
            "Epoch: 9 \t loss: 0.2634933590888977\n",
            "Test set:  0.976\n",
            "\n",
            "Epoch: 10 \t itr: 55/563 \t loss: 0.2645585536956787\n",
            "Epoch: 10 \t itr: 111/563 \t loss: 0.26127535104751587\n",
            "Epoch: 10 \t itr: 167/563 \t loss: 0.26092833280563354\n",
            "Epoch: 10 \t itr: 223/563 \t loss: 0.2623125910758972\n",
            "Epoch: 10 \t itr: 279/563 \t loss: 0.26158010959625244\n",
            "Epoch: 10 \t itr: 335/563 \t loss: 0.260612815618515\n",
            "Epoch: 10 \t itr: 391/563 \t loss: 0.2603210210800171\n",
            "Epoch: 10 \t itr: 447/563 \t loss: 0.2603655755519867\n",
            "Epoch: 10 \t itr: 503/563 \t loss: 0.26084935665130615\n",
            "Epoch: 10 \t itr: 559/563 \t loss: 0.26055046916007996\n",
            "\n",
            "Epoch: 10 \t loss: 0.26129981875419617\n",
            "Test set:  0.976\n",
            "\n",
            "Epoch: 11 \t itr: 55/563 \t loss: 0.2612330913543701\n",
            "Epoch: 11 \t itr: 111/563 \t loss: 0.26000577211380005\n",
            "Epoch: 11 \t itr: 167/563 \t loss: 0.25902459025382996\n",
            "Epoch: 11 \t itr: 223/563 \t loss: 0.2595086991786957\n",
            "Epoch: 11 \t itr: 279/563 \t loss: 0.26046839356422424\n",
            "Epoch: 11 \t itr: 335/563 \t loss: 0.2583668828010559\n",
            "Epoch: 11 \t itr: 391/563 \t loss: 0.2575511932373047\n",
            "Epoch: 11 \t itr: 447/563 \t loss: 0.25781822204589844\n",
            "Epoch: 11 \t itr: 503/563 \t loss: 0.2578652501106262\n",
            "Epoch: 11 \t itr: 559/563 \t loss: 0.25737082958221436\n",
            "\n",
            "Epoch: 11 \t loss: 0.25888490676879883\n",
            "Test set:  0.978\n",
            "\n",
            "Epoch: 12 \t itr: 55/563 \t loss: 0.25909143686294556\n",
            "Epoch: 12 \t itr: 111/563 \t loss: 0.25691574811935425\n",
            "Epoch: 12 \t itr: 167/563 \t loss: 0.25676774978637695\n",
            "Epoch: 12 \t itr: 223/563 \t loss: 0.2569555938243866\n",
            "Epoch: 12 \t itr: 279/563 \t loss: 0.2583472430706024\n",
            "Epoch: 12 \t itr: 335/563 \t loss: 0.25624096393585205\n",
            "Epoch: 12 \t itr: 391/563 \t loss: 0.25667375326156616\n",
            "Epoch: 12 \t itr: 447/563 \t loss: 0.2561356723308563\n",
            "Epoch: 12 \t itr: 503/563 \t loss: 0.2567417025566101\n",
            "Epoch: 12 \t itr: 559/563 \t loss: 0.2560092508792877\n",
            "\n",
            "Epoch: 12 \t loss: 0.2569534182548523\n",
            "Test set:  0.981\n",
            "\n",
            "Epoch: 13 \t itr: 55/563 \t loss: 0.25756800174713135\n",
            "Epoch: 13 \t itr: 111/563 \t loss: 0.2555018365383148\n",
            "Epoch: 13 \t itr: 167/563 \t loss: 0.25516289472579956\n",
            "Epoch: 13 \t itr: 223/563 \t loss: 0.2547052502632141\n",
            "Epoch: 13 \t itr: 279/563 \t loss: 0.2585222125053406\n",
            "Epoch: 13 \t itr: 335/563 \t loss: 0.25687170028686523\n",
            "Epoch: 13 \t itr: 391/563 \t loss: 0.2555514872074127\n",
            "Epoch: 13 \t itr: 447/563 \t loss: 0.25523921847343445\n",
            "Epoch: 13 \t itr: 503/563 \t loss: 0.25548088550567627\n",
            "Epoch: 13 \t itr: 559/563 \t loss: 0.254660427570343\n",
            "\n",
            "Epoch: 13 \t loss: 0.25589248538017273\n",
            "Test set:  0.984\n",
            "\n",
            "Epoch: 14 \t itr: 55/563 \t loss: 0.25675055384635925\n",
            "Epoch: 14 \t itr: 111/563 \t loss: 0.25423744320869446\n",
            "Epoch: 14 \t itr: 167/563 \t loss: 0.25426560640335083\n",
            "Epoch: 14 \t itr: 223/563 \t loss: 0.2537783682346344\n",
            "Epoch: 14 \t itr: 279/563 \t loss: 0.25623226165771484\n",
            "Epoch: 14 \t itr: 335/563 \t loss: 0.2537459433078766\n",
            "Epoch: 14 \t itr: 391/563 \t loss: 0.25351595878601074\n",
            "Epoch: 14 \t itr: 447/563 \t loss: 0.25383660197257996\n",
            "Epoch: 14 \t itr: 503/563 \t loss: 0.2537783682346344\n",
            "Epoch: 14 \t itr: 559/563 \t loss: 0.2536563575267792\n",
            "\n",
            "Epoch: 14 \t loss: 0.2543482184410095\n",
            "Test set:  0.983\n",
            "\n",
            "Epoch: 15 \t itr: 55/563 \t loss: 0.25519734621047974\n",
            "Epoch: 15 \t itr: 111/563 \t loss: 0.2532450258731842\n",
            "Epoch: 15 \t itr: 167/563 \t loss: 0.2533677816390991\n",
            "Epoch: 15 \t itr: 223/563 \t loss: 0.2523491680622101\n",
            "Epoch: 15 \t itr: 279/563 \t loss: 0.254680871963501\n",
            "Epoch: 15 \t itr: 335/563 \t loss: 0.25220391154289246\n",
            "Epoch: 15 \t itr: 391/563 \t loss: 0.25218555331230164\n",
            "Epoch: 15 \t itr: 447/563 \t loss: 0.2528916895389557\n",
            "Epoch: 15 \t itr: 503/563 \t loss: 0.2528897523880005\n",
            "Epoch: 15 \t itr: 559/563 \t loss: 0.25267264246940613\n",
            "\n",
            "Epoch: 15 \t loss: 0.253139466047287\n",
            "Test set:  0.984\n",
            "\n",
            "Epoch: 16 \t itr: 55/563 \t loss: 0.25469839572906494\n",
            "Epoch: 16 \t itr: 111/563 \t loss: 0.2526003122329712\n",
            "Epoch: 16 \t itr: 167/563 \t loss: 0.2527639865875244\n",
            "Epoch: 16 \t itr: 223/563 \t loss: 0.25175872445106506\n",
            "Epoch: 16 \t itr: 279/563 \t loss: 0.25354424118995667\n",
            "Epoch: 16 \t itr: 335/563 \t loss: 0.2520221471786499\n",
            "Epoch: 16 \t itr: 391/563 \t loss: 0.2517414689064026\n",
            "Epoch: 16 \t itr: 447/563 \t loss: 0.2521495223045349\n",
            "Epoch: 16 \t itr: 503/563 \t loss: 0.25208407640457153\n",
            "Epoch: 16 \t itr: 559/563 \t loss: 0.2527455985546112\n",
            "\n",
            "Epoch: 16 \t loss: 0.25258228182792664\n",
            "Test set:  0.982\n",
            "\n",
            "Epoch: 17 \t itr: 55/563 \t loss: 0.25358694791793823\n",
            "Epoch: 17 \t itr: 111/563 \t loss: 0.2515908181667328\n",
            "Epoch: 17 \t itr: 167/563 \t loss: 0.25188127160072327\n",
            "Epoch: 17 \t itr: 223/563 \t loss: 0.25050970911979675\n",
            "Epoch: 17 \t itr: 279/563 \t loss: 0.25288188457489014\n",
            "Epoch: 17 \t itr: 335/563 \t loss: 0.2510364353656769\n",
            "Epoch: 17 \t itr: 391/563 \t loss: 0.2510282099246979\n",
            "Epoch: 17 \t itr: 447/563 \t loss: 0.2514879107475281\n",
            "Epoch: 17 \t itr: 503/563 \t loss: 0.25133875012397766\n",
            "Epoch: 17 \t itr: 559/563 \t loss: 0.251528799533844\n",
            "\n",
            "Epoch: 17 \t loss: 0.2516654133796692\n",
            "Test set:  0.979\n",
            "\n",
            "Epoch: 18 \t itr: 55/563 \t loss: 0.2532309293746948\n",
            "Epoch: 18 \t itr: 111/563 \t loss: 0.25117582082748413\n",
            "Epoch: 18 \t itr: 167/563 \t loss: 0.2510145902633667\n",
            "Epoch: 18 \t itr: 223/563 \t loss: 0.24989397823810577\n",
            "Epoch: 18 \t itr: 279/563 \t loss: 0.2521824836730957\n",
            "Epoch: 18 \t itr: 335/563 \t loss: 0.2502393126487732\n",
            "Epoch: 18 \t itr: 391/563 \t loss: 0.250660240650177\n",
            "Epoch: 18 \t itr: 447/563 \t loss: 0.25091180205345154\n",
            "Epoch: 18 \t itr: 503/563 \t loss: 0.2507784068584442\n",
            "Epoch: 18 \t itr: 559/563 \t loss: 0.2507544159889221\n",
            "\n",
            "Epoch: 18 \t loss: 0.2510594129562378\n",
            "Test set:  0.986\n",
            "\n",
            "Epoch: 19 \t itr: 55/563 \t loss: 0.2520376145839691\n",
            "Epoch: 19 \t itr: 111/563 \t loss: 0.2508390545845032\n",
            "Epoch: 19 \t itr: 167/563 \t loss: 0.2505258023738861\n",
            "Epoch: 19 \t itr: 223/563 \t loss: 0.24950969219207764\n",
            "Epoch: 19 \t itr: 279/563 \t loss: 0.2516704797744751\n",
            "Epoch: 19 \t itr: 335/563 \t loss: 0.24972672760486603\n",
            "Epoch: 19 \t itr: 391/563 \t loss: 0.24996723234653473\n",
            "Epoch: 19 \t itr: 447/563 \t loss: 0.25058513879776\n",
            "Epoch: 19 \t itr: 503/563 \t loss: 0.2502971589565277\n",
            "Epoch: 19 \t itr: 559/563 \t loss: 0.25040531158447266\n",
            "\n",
            "Epoch: 19 \t loss: 0.25053220987319946\n",
            "Test set:  0.987\n",
            "\n",
            "Epoch: 20 \t itr: 55/563 \t loss: 0.2517504096031189\n",
            "Epoch: 20 \t itr: 111/563 \t loss: 0.2504374086856842\n",
            "Epoch: 20 \t itr: 167/563 \t loss: 0.2501760721206665\n",
            "Epoch: 20 \t itr: 223/563 \t loss: 0.24900516867637634\n",
            "Epoch: 20 \t itr: 279/563 \t loss: 0.25100061297416687\n",
            "Epoch: 20 \t itr: 335/563 \t loss: 0.24914567172527313\n",
            "Epoch: 20 \t itr: 391/563 \t loss: 0.2495645433664322\n",
            "Epoch: 20 \t itr: 447/563 \t loss: 0.25013241171836853\n",
            "Epoch: 20 \t itr: 503/563 \t loss: 0.24981741607189178\n",
            "Epoch: 20 \t itr: 559/563 \t loss: 0.2501325011253357\n",
            "\n",
            "Epoch: 20 \t loss: 0.25009283423423767\n",
            "Test set:  0.981\n",
            "\n",
            "Epoch: 21 \t itr: 55/563 \t loss: 0.2512276768684387\n",
            "Epoch: 21 \t itr: 111/563 \t loss: 0.24998119473457336\n",
            "Epoch: 21 \t itr: 167/563 \t loss: 0.24954307079315186\n",
            "Epoch: 21 \t itr: 223/563 \t loss: 0.24881960451602936\n",
            "Epoch: 21 \t itr: 279/563 \t loss: 0.2508530616760254\n",
            "Epoch: 21 \t itr: 335/563 \t loss: 0.24903012812137604\n",
            "Epoch: 21 \t itr: 391/563 \t loss: 0.2493506371974945\n",
            "Epoch: 21 \t itr: 447/563 \t loss: 0.24974387884140015\n",
            "Epoch: 21 \t itr: 503/563 \t loss: 0.24946074187755585\n",
            "Epoch: 21 \t itr: 559/563 \t loss: 0.24957747757434845\n",
            "\n",
            "Epoch: 21 \t loss: 0.24973377585411072\n",
            "Test set:  0.984\n",
            "\n",
            "Epoch: 22 \t itr: 55/563 \t loss: 0.2507081627845764\n",
            "Epoch: 22 \t itr: 111/563 \t loss: 0.2496565878391266\n",
            "Epoch: 22 \t itr: 167/563 \t loss: 0.2493075579404831\n",
            "Epoch: 22 \t itr: 223/563 \t loss: 0.24836008250713348\n",
            "Epoch: 22 \t itr: 279/563 \t loss: 0.25026270747184753\n",
            "Epoch: 22 \t itr: 335/563 \t loss: 0.24834348261356354\n",
            "Epoch: 22 \t itr: 391/563 \t loss: 0.2486257702112198\n",
            "Epoch: 22 \t itr: 447/563 \t loss: 0.2494664192199707\n",
            "Epoch: 22 \t itr: 503/563 \t loss: 0.2490556240081787\n",
            "Epoch: 22 \t itr: 559/563 \t loss: 0.24931669235229492\n",
            "\n",
            "Epoch: 22 \t loss: 0.24928686022758484\n",
            "Test set:  0.984\n",
            "\n",
            "Epoch: 23 \t itr: 55/563 \t loss: 0.25039926171302795\n",
            "Epoch: 23 \t itr: 111/563 \t loss: 0.2491087168455124\n",
            "Epoch: 23 \t itr: 167/563 \t loss: 0.248788520693779\n",
            "Epoch: 23 \t itr: 223/563 \t loss: 0.24811381101608276\n",
            "Epoch: 23 \t itr: 279/563 \t loss: 0.25001060962677\n",
            "Epoch: 23 \t itr: 335/563 \t loss: 0.2480609118938446\n",
            "Epoch: 23 \t itr: 391/563 \t loss: 0.24827151000499725\n",
            "Epoch: 23 \t itr: 447/563 \t loss: 0.2488880455493927\n",
            "Epoch: 23 \t itr: 503/563 \t loss: 0.24881820380687714\n",
            "Epoch: 23 \t itr: 559/563 \t loss: 0.24898189306259155\n",
            "\n",
            "Epoch: 23 \t loss: 0.24892188608646393\n",
            "Test set:  0.983\n",
            "\n",
            "Epoch: 24 \t itr: 55/563 \t loss: 0.24993069469928741\n",
            "Epoch: 24 \t itr: 111/563 \t loss: 0.24894003570079803\n",
            "Epoch: 24 \t itr: 167/563 \t loss: 0.24841707944869995\n",
            "Epoch: 24 \t itr: 223/563 \t loss: 0.24773545563220978\n",
            "Epoch: 24 \t itr: 279/563 \t loss: 0.24950946867465973\n",
            "Epoch: 24 \t itr: 335/563 \t loss: 0.24769039452075958\n",
            "Epoch: 24 \t itr: 391/563 \t loss: 0.24801966547966003\n",
            "Epoch: 24 \t itr: 447/563 \t loss: 0.2486061304807663\n",
            "Epoch: 24 \t itr: 503/563 \t loss: 0.24853408336639404\n",
            "Epoch: 24 \t itr: 559/563 \t loss: 0.24872785806655884\n",
            "\n",
            "Epoch: 24 \t loss: 0.24858839809894562\n",
            "Test set:  0.983\n",
            "\n",
            "Epoch: 25 \t itr: 55/563 \t loss: 0.24980418384075165\n",
            "Epoch: 25 \t itr: 111/563 \t loss: 0.2486790418624878\n",
            "Epoch: 25 \t itr: 167/563 \t loss: 0.24818968772888184\n",
            "Epoch: 25 \t itr: 223/563 \t loss: 0.24750107526779175\n",
            "Epoch: 25 \t itr: 279/563 \t loss: 0.2493515908718109\n",
            "Epoch: 25 \t itr: 335/563 \t loss: 0.2473963052034378\n",
            "Epoch: 25 \t itr: 391/563 \t loss: 0.24779371917247772\n",
            "Epoch: 25 \t itr: 447/563 \t loss: 0.24843516945838928\n",
            "Epoch: 25 \t itr: 503/563 \t loss: 0.24833589792251587\n",
            "Epoch: 25 \t itr: 559/563 \t loss: 0.24839898943901062\n",
            "\n",
            "Epoch: 25 \t loss: 0.24836640059947968\n",
            "Test set:  0.986\n",
            "\n",
            "Epoch: 26 \t itr: 55/563 \t loss: 0.24933463335037231\n",
            "Epoch: 26 \t itr: 111/563 \t loss: 0.24829675257205963\n",
            "Epoch: 26 \t itr: 167/563 \t loss: 0.24781936407089233\n",
            "Epoch: 26 \t itr: 223/563 \t loss: 0.2471243143081665\n",
            "Epoch: 26 \t itr: 279/563 \t loss: 0.248983696103096\n",
            "Epoch: 26 \t itr: 335/563 \t loss: 0.2472631186246872\n",
            "Epoch: 26 \t itr: 391/563 \t loss: 0.24751994013786316\n",
            "Epoch: 26 \t itr: 447/563 \t loss: 0.2480170726776123\n",
            "Epoch: 26 \t itr: 503/563 \t loss: 0.24813303351402283\n",
            "Epoch: 26 \t itr: 559/563 \t loss: 0.24820145964622498\n",
            "\n",
            "Epoch: 26 \t loss: 0.2480463981628418\n",
            "Test set:  0.987\n",
            "\n",
            "Epoch: 27 \t itr: 55/563 \t loss: 0.24919721484184265\n",
            "Epoch: 27 \t itr: 111/563 \t loss: 0.24795706570148468\n",
            "Epoch: 27 \t itr: 167/563 \t loss: 0.2477579265832901\n",
            "Epoch: 27 \t itr: 223/563 \t loss: 0.24698808789253235\n",
            "Epoch: 27 \t itr: 279/563 \t loss: 0.248928502202034\n",
            "Epoch: 27 \t itr: 335/563 \t loss: 0.24701401591300964\n",
            "Epoch: 27 \t itr: 391/563 \t loss: 0.24731780588626862\n",
            "Epoch: 27 \t itr: 447/563 \t loss: 0.24797260761260986\n",
            "Epoch: 27 \t itr: 503/563 \t loss: 0.24788188934326172\n",
            "Epoch: 27 \t itr: 559/563 \t loss: 0.24786128103733063\n",
            "\n",
            "Epoch: 27 \t loss: 0.2478644847869873\n",
            "Test set:  0.985\n",
            "\n",
            "Epoch: 28 \t itr: 55/563 \t loss: 0.24885135889053345\n",
            "Epoch: 28 \t itr: 111/563 \t loss: 0.24780318140983582\n",
            "Epoch: 28 \t itr: 167/563 \t loss: 0.24754811823368073\n",
            "Epoch: 28 \t itr: 223/563 \t loss: 0.24659433960914612\n",
            "Epoch: 28 \t itr: 279/563 \t loss: 0.24861553311347961\n",
            "Epoch: 28 \t itr: 335/563 \t loss: 0.2468177229166031\n",
            "Epoch: 28 \t itr: 391/563 \t loss: 0.24714219570159912\n",
            "Epoch: 28 \t itr: 447/563 \t loss: 0.24764792621135712\n",
            "Epoch: 28 \t itr: 503/563 \t loss: 0.2477790117263794\n",
            "Epoch: 28 \t itr: 559/563 \t loss: 0.2476058155298233\n",
            "\n",
            "Epoch: 28 \t loss: 0.2476188689470291\n",
            "Test set:  0.984\n",
            "\n",
            "Epoch: 29 \t itr: 55/563 \t loss: 0.24873332679271698\n",
            "Epoch: 29 \t itr: 111/563 \t loss: 0.2475290298461914\n",
            "Epoch: 29 \t itr: 167/563 \t loss: 0.24734310805797577\n",
            "Epoch: 29 \t itr: 223/563 \t loss: 0.24650371074676514\n",
            "Epoch: 29 \t itr: 279/563 \t loss: 0.2485884130001068\n",
            "Epoch: 29 \t itr: 335/563 \t loss: 0.24681822955608368\n",
            "Epoch: 29 \t itr: 391/563 \t loss: 0.2468349039554596\n",
            "Epoch: 29 \t itr: 447/563 \t loss: 0.24750208854675293\n",
            "Epoch: 29 \t itr: 503/563 \t loss: 0.24746938049793243\n",
            "Epoch: 29 \t itr: 559/563 \t loss: 0.2474002093076706\n",
            "\n",
            "Epoch: 29 \t loss: 0.24744902551174164\n",
            "Test set:  0.986\n",
            "\n"
          ]
        }
      ]
    }
  ]
}